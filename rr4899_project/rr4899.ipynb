{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project\n",
    "# Siva Teja Yadav - rr4899\n",
    "# Laxman Reddy Aileni - nh1718"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stroing data\n",
    "test_data=pd.read_csv('C:/Users/STSC/Downloads/diabetes_test.csv')\n",
    "train_data=pd.read_csv('C:/Users/STSC/Downloads/diabetes_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(649, 8)\n"
     ]
    }
   ],
   "source": [
    "train_x=train_data.iloc[:,:-1]\n",
    "train_y=train_data.iloc[:,-1]\n",
    "test_x=test_data.iloc[:,:-1]\n",
    "test_y=test_data.iloc[:,-1]\n",
    "print(train_x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question-1\n",
    "## MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test error 0.3445378151260504\n",
      "training error 0.27580893682588603\n"
     ]
    }
   ],
   "source": [
    "#Set 1:\n",
    "mlp1=MLPClassifier(hidden_layer_sizes=100, activation='relu',solver='adam', alpha=0.001, max_iter=500, learning_rate_init=0.001)\n",
    "mlp1.fit(train_x,train_y)\n",
    "mlp_pred1=mlp1.predict(test_x)\n",
    "pred=mlp1.predict(train_x)\n",
    "print(f\"test error {1-accuracy_score(test_y,mlp_pred1)}\")\n",
    "print(f\"training error {1-accuracy_score(train_y,pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test error 0.3025210084033614\n",
      "training error 0.23112480739599384\n"
     ]
    }
   ],
   "source": [
    "#Set 2:\n",
    "mlp2=MLPClassifier(hidden_layer_sizes=50, activation='logistic',solver='adam', alpha=0.0001, max_iter=300, learning_rate_init=0.01)\n",
    "mlp2.fit(train_x,train_y)\n",
    "mlp_pred2=mlp2.predict(test_x)\n",
    "pred=mlp2.predict(train_x)\n",
    "print(f'test error {1-accuracy_score(test_y,mlp_pred2)}')\n",
    "print(f'training error {1-accuracy_score(train_y,pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test error 0.4285714285714286\n",
      "traininig error 0.2989214175654854\n"
     ]
    }
   ],
   "source": [
    "#Set 3:\n",
    "mlp3=MLPClassifier(hidden_layer_sizes=75, activation='tanh',solver='sgd', alpha=0.001, max_iter=800, learning_rate_init=0.0001)\n",
    "mlp3.fit(train_x,train_y)\n",
    "mlp_pred3=mlp3.predict(test_x)\n",
    "pred=mlp3.predict(train_x)\n",
    "print(f\"test error {1-accuracy_score(test_y,mlp_pred3)}\")\n",
    "print(f'traininig error {1-accuracy_score(train_y,pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test error 0.32773109243697474\n",
      "traininig error 0.19414483821263484\n"
     ]
    }
   ],
   "source": [
    "#Set 4:\n",
    "mlp4=MLPClassifier(hidden_layer_sizes=90,activation='tanh',solver='adam',max_iter=1000, alpha=1, random_state=0)\n",
    "mlp4.fit(train_x,train_y)\n",
    "mlp_pred4=mlp4.predict(test_x)\n",
    "pred=mlp4.predict(train_x)\n",
    "print(f'test error {1-accuracy_score(test_y,mlp_pred4)}')\n",
    "print(f'traininig error {1-accuracy_score(train_y,pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test error 0.2941176470588235\n",
      "traininig error 0.28659476117103233\n"
     ]
    }
   ],
   "source": [
    "#Set 5:\n",
    "mlp5=MLPClassifier(hidden_layer_sizes=10,activation='identity',max_iter=900, alpha=1, random_state=0)\n",
    "mlp5.fit(train_x,train_y)\n",
    "mlp_pred5=mlp5.predict(test_x)\n",
    "pred=mlp5.predict(train_x)\n",
    "print(f'test error {1-accuracy_score(test_y,mlp_pred5)}')\n",
    "print(f'traininig error {1-accuracy_score(train_y,pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question-2\n",
    "## Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test error 0.26890756302521013\n",
      "traininig error 0.0\n"
     ]
    }
   ],
   "source": [
    "#Set 1:\n",
    "dt1=DecisionTreeClassifier( criterion='gini', splitter='best', max_depth=None, min_samples_split=2,  max_features=None, random_state=None, max_leaf_nodes=None)\n",
    "dt1.fit(train_x,train_y)\n",
    "dt_pred1=dt1.predict(test_x)\n",
    "pred=dt1.predict(train_x)\n",
    "print(f'test error {1-accuracy_score(test_y,dt_pred1)}')\n",
    "print(f'traininig error {1-accuracy_score(train_y,pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test error 0.37815126050420167\n",
      "traininig error 0.33744221879815095\n"
     ]
    }
   ],
   "source": [
    "#Set 2:\n",
    "dt2=DecisionTreeClassifier( criterion='entropy', splitter='random', max_depth=10, min_samples_split=5,  max_features=2, random_state=0, max_leaf_nodes=3)\n",
    "dt2.fit(train_x,train_y)\n",
    "dt_pred2=dt2.predict(test_x)\n",
    "pred=dt2.predict(train_x)\n",
    "print(f'test error {1-accuracy_score(test_y,dt_pred2)}')\n",
    "print(f'traininig error {1-accuracy_score(train_y,pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test error 0.2941176470588235\n",
      "traininig error 0.19260400616332818\n"
     ]
    }
   ],
   "source": [
    "#Set 3:\n",
    "dt3=DecisionTreeClassifier( criterion='gini', splitter='random', max_depth=100, min_samples_split=20,  max_features=3, random_state=1, max_leaf_nodes=300)\n",
    "dt3.fit(train_x,train_y)\n",
    "dt_pred3=dt3.predict(test_x)\n",
    "pred=dt3.predict(train_x)\n",
    "\n",
    "print(f'test error {1-accuracy_score(test_y,dt_pred3)}')\n",
    "print(f'traininig error {1-accuracy_score(train_y,pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test error 0.2100840336134454\n",
      "traininig error 0.2357473035439137\n"
     ]
    }
   ],
   "source": [
    "#Set 4:\n",
    "dt4=DecisionTreeClassifier( criterion='gini', splitter='best', max_depth=100, min_samples_split=200,  max_features=4, random_state=1, max_leaf_nodes=300)\n",
    "dt4.fit(train_x,train_y)\n",
    "dt_pred4=dt4.predict(test_x)\n",
    "pred=dt4.predict(train_x)\n",
    "print(f'test error {1-accuracy_score(test_y,dt_pred4)}')\n",
    "print(f'traininig error {1-accuracy_score(train_y,pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test error 0.3529411764705882\n",
      "traininig error 0.28659476117103233\n"
     ]
    }
   ],
   "source": [
    "#Set 5:\n",
    "dt5=DecisionTreeClassifier( criterion='entropy', splitter='random', max_depth=400, min_samples_split=300,  max_features=5, random_state=1, max_leaf_nodes=300)\n",
    "dt5.fit(train_x,train_y)\n",
    "dt_pred5=dt5.predict(test_x)\n",
    "pred=dt5.predict(train_x)\n",
    "print(f'test error {1-accuracy_score(test_y,dt_pred5)}')\n",
    "print(f'traininig error {1-accuracy_score(train_y,pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question3\n",
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test error 0.24369747899159666\n",
      "traininig error 0.0\n"
     ]
    }
   ],
   "source": [
    "#Set 1:\n",
    "rf1=RandomForestClassifier(n_estimators=100, criterion='gini', max_depth=None, min_samples_split=2, max_features='auto')\n",
    "rf1.fit(train_x,train_y)\n",
    "rf_pred1=rf1.predict(test_x)\n",
    "pred=rf1.predict(train_x)\n",
    "print(f'test error {1-accuracy_score(test_y,rf_pred1)}')\n",
    "print(f'traininig error {1-accuracy_score(train_y,pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test error 0.23529411764705888\n",
      "traininig error 0.0030816640986132127\n"
     ]
    }
   ],
   "source": [
    "#Set 2:\n",
    "rf2=RandomForestClassifier(n_estimators=1000, criterion='entropy', max_depth=100, min_samples_split=5, max_features='auto')\n",
    "rf2.fit(train_x,train_y)\n",
    "rf_pred2=rf2.predict(test_x)\n",
    "pred=rf2.predict(train_x)\n",
    "print(f'test error {1-accuracy_score(test_y,rf_pred2)}')\n",
    "print(f'traininig error {1-accuracy_score(train_y,pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test error 0.2184873949579832\n",
      "traininig error 0.09707241910631736\n"
     ]
    }
   ],
   "source": [
    "#Set 3:\n",
    "rf3=RandomForestClassifier(n_estimators=1000, criterion='entropy', max_depth=10, min_samples_split=20, max_features='sqrt')\n",
    "rf3.fit(train_x,train_y)\n",
    "rf_pred3=rf3.predict(test_x)\n",
    "pred=rf3.predict(train_x)\n",
    "print(f'test error {1-accuracy_score(test_y,rf_pred3)}')\n",
    "print(f'traininig error {1-accuracy_score(train_y,pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test error 0.19327731092436973\n",
      "traininig error 0.1956856702619415\n"
     ]
    }
   ],
   "source": [
    "#Set 4:\n",
    "rf4=RandomForestClassifier(n_estimators=10, criterion='gini', max_depth=5000, min_samples_split=100, max_features='log2')\n",
    "rf4.fit(train_x,train_y)\n",
    "rf_pred4=rf4.predict(test_x)\n",
    "pred=rf4.predict(train_x)\n",
    "print(f'test error {1-accuracy_score(test_y,rf_pred4)}')\n",
    "print(f'traininig error {1-accuracy_score(train_y,pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test error 0.2184873949579832\n",
      "traininig error 0.0\n"
     ]
    }
   ],
   "source": [
    "#Set 5:\n",
    "rf5=RandomForestClassifier(n_estimators=50, criterion='gini', max_depth=100, min_samples_split=2, max_features='auto')\n",
    "rf5.fit(train_x,train_y)\n",
    "rf_pred5=rf5.predict(test_x)\n",
    "pred=rf5.predict(train_x)\n",
    "print(f'test error {1-accuracy_score(test_y,rf_pred5)}')\n",
    "print(f'traininig error {1-accuracy_score(train_y,pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question-4\n",
    "## Gradient boosting classifier \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test error 0.25210084033613445\n",
      "traininig error 0.08012326656394453\n"
     ]
    }
   ],
   "source": [
    "#Set 1:\n",
    "gb1=GradientBoostingClassifier(loss='deviance', learning_rate=0.1, n_estimators=100, subsample=1.0, criterion='friedman_mse', min_samples_split=2, min_samples_leaf=1)\n",
    "gb1.fit(train_x,train_y)\n",
    "gb_pred1=gb1.predict(test_x)\n",
    "pred=gb1.predict(train_x)\n",
    "print(f'test error {1-accuracy_score(test_y,gb_pred1)}')\n",
    "print(f'traininig error {1-accuracy_score(train_y,pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test error 0.23529411764705888\n",
      "traininig error 0.13867488443759635\n"
     ]
    }
   ],
   "source": [
    "##Set 2:\n",
    "gb2=GradientBoostingClassifier(loss='exponential', learning_rate=0.01, n_estimators=500, subsample=1.0, criterion='mse', min_samples_split=5, min_samples_leaf=5)\n",
    "gb2.fit(train_x,train_y)\n",
    "gb_pred2=gb2.predict(test_x)\n",
    "pred=gb2.predict(train_x)\n",
    "print(f'test error {1-accuracy_score(test_y,gb_pred2)}')\n",
    "print(f'traininig error {1-accuracy_score(train_y,pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test error 0.26890756302521013\n",
      "traininig error 0.23112480739599384\n"
     ]
    }
   ],
   "source": [
    "##Set 3:\n",
    "gb3=GradientBoostingClassifier(loss='deviance', learning_rate=0.001, n_estimators=1000, subsample=1.0, criterion='mae', min_samples_split=20, min_samples_leaf=5)\n",
    "gb3.fit(train_x,train_y)\n",
    "gb_pred3=gb3.predict(test_x)\n",
    "pred=gb3.predict(train_x)\n",
    "print(f'test error {1-accuracy_score(test_y,gb_pred3)}')\n",
    "print(f'traininig error {1-accuracy_score(train_y,pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test error 0.37815126050420167\n",
      "traininig error 0.3436055469953775\n"
     ]
    }
   ],
   "source": [
    "#Set 4:\n",
    "gb4=GradientBoostingClassifier(loss='exponential', learning_rate=0.01, n_estimators=10, subsample=1.0, criterion='mse', min_samples_split=22, min_samples_leaf=93)\n",
    "gb4.fit(train_x,train_y)\n",
    "gb_pred4=gb4.predict(test_x)\n",
    "pred=gb4.predict(train_x)\n",
    "print(f'test error {1-accuracy_score(test_y,gb_pred4)}')\n",
    "print(f'traininig error {1-accuracy_score(train_y,pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test error 0.3445378151260504\n",
      "traininig error 0.28197226502311246\n"
     ]
    }
   ],
   "source": [
    "#Set 5:\n",
    "gb5=GradientBoostingClassifier(loss='deviance', learning_rate=0.01, n_estimators=50, subsample=1.0, criterion='mae', min_samples_split=90, min_samples_leaf=44)\n",
    "gb5.fit(train_x,train_y)\n",
    "gb_pred5=gb5.predict(test_x)\n",
    "pred=gb5.predict(train_x)\n",
    "print(f'test error {1-accuracy_score(test_y,gb_pred5)}')\n",
    "print(f'traininig error {1-accuracy_score(train_y,pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question-5\n",
    "### a) With equal weight to each classifier, i.e. 1/4*g1+1/4*g2+1/4*g3+1/4*g4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error: 0.31 [Multilayer perceptron]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\STSC\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (900) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STSC\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (900) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Error: 0.33 [Multilayer perceptron]\n",
      "Training Error: 0.28 [decision tree]\n",
      "Testing Error: 0.38 [decision tree]\n",
      "Training Error: 0.24 [random forest]\n",
      "Testing Error: 0.32 [random forest]\n",
      "Training Error: 0.23 [gradient Boost]\n",
      "Testing Error: 0.32 [gradient Boost]\n",
      "Training Error: 0.25 [Ensemble]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\STSC\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (900) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STSC\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (900) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Error: 0.32 [Ensemble]\n"
     ]
    }
   ],
   "source": [
    "eclf = VotingClassifier(\n",
    "...     estimators=[('mlp', mlp5), ('dt',dt4 ), ('rf',rf5),('gb', gb2)],\n",
    "...     voting='hard',weights=[1, 1, 1,1])\n",
    "\n",
    "for clf, label in zip([mlp5,dt4,rf5,gb2,eclf], ['Multilayer perceptron','decision tree','random forest','gradient Boost','Ensemble']):\n",
    "    \n",
    "    scores = cross_val_score(clf, train_x, train_y, scoring='accuracy', cv=5)\n",
    "    print(\"Training Error: %0.2f [%s]\" % (1-scores.mean(),label))\n",
    "        \n",
    "    scores_test = cross_val_score(clf, test_x, test_y, scoring='accuracy', cv=5)\n",
    "    print(\"Testing Error: %0.2f [%s]\" % (1-scores_test.mean(),label))\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) With weights proportional to 1/(1+trainingerror)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_pred=mlp5.predict(train_x)\n",
    "dt_pred=dt4.predict(train_x)\n",
    "gb_pred=gb2.predict(train_x)\n",
    "rf_pred=rf5.predict(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.28659476117103233\n",
      "0.2357473035439137\n",
      "0.13867488443759635\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "mlp_error=1-accuracy_score(train_y,mlp_pred)\n",
    "dt_error=1-accuracy_score(train_y,dt_pred)\n",
    "gb_error=1-accuracy_score(train_y,gb_pred)\n",
    "rf_error=1-accuracy_score(train_y,rf_pred)\n",
    "print(mlp_error)\n",
    "print(dt_error)\n",
    "print(gb_error)\n",
    "print(rf_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error: 0.31  [Multilayer perceptron]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\STSC\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (900) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STSC\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (900) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Error: 0.33 [Multilayer perceptron]\n",
      "\n",
      "\n",
      "Training Error: 0.28  [Decision Tree]\n",
      "Testing Error: 0.38 [Decision Tree]\n",
      "\n",
      "\n",
      "Training Error: 0.23  [random forest]\n",
      "Testing Error: 0.32 [random forest]\n",
      "\n",
      "\n",
      "Training Error: 0.24  [gradient Boosting]\n",
      "Testing Error: 0.32 [gradient Boosting]\n",
      "\n",
      "\n",
      "Training Error: 0.25  [Ensemble]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\STSC\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (900) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\STSC\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (900) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Error: 0.29 [Ensemble]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eclf = VotingClassifier(\n",
    "...     estimators=[('mlp', mlp5), ('dt',dt4 ),('rf',rf5), ('gb', gb2)],\n",
    "...     voting='hard',weights=[1/(1+mlp_error), 1/(1+dt_error),1/(1+rf_error) ,1/(1+gb_error)])\n",
    "for clf, label in zip([mlp5, dt4, gb2,rf5, eclf], ['Multilayer perceptron', 'Decision Tree','random forest', 'gradient Boosting', 'Ensemble']):\n",
    "...     scores = cross_val_score(clf, train_x, train_y, scoring='accuracy', cv=5)\n",
    "...     print(\"Training Error: %0.2f  [%s]\" % (1-scores.mean(), label))\n",
    "        \n",
    "    scores_test = cross_val_score(clf, test_x, test_y, scoring='accuracy', cv=5)\n",
    "    print(\"Testing Error: %0.2f [%s]\" % (1-scores_test.mean(),label))\n",
    "    print(\"\\n\")\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
